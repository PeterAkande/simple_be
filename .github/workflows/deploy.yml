name: Docker image build and publish
on:
  workflow_dispatch:
    inputs:
      path_to_dockerfile:
        description: Path to the Dockerfile (default = 'Dockerfile')
        default: "Dockerfile"
        type: string
      docker_build_dir:
        description: Docker build directory (default = '.')
        default: "."
        type: string
      lifecycle_policy_file:
        description: Path to the lifecycle policy JSON file (default = 'policy.json')
        default: "../build/policy.json"
        type: string
      backend_s3_bucket:
        description: Name of the S3 bucket for Terraform backend
        default: "terraform-backend-primary"
        type: string
      aws_account_id:
        description: AWS Account ID
        type: string
        default: "954614735297"
      aws_region:
        description: Target AWS Region
        default: "us-west-2"
        type: string
      backend_dynamodb_table:
        description: DynamoDB table for State lock
        default: "terraform-backend-ddb"
        type: string
      ecs_cluster_name:
        description: ECS Cluster Name
        default: "app_cluster"
        type: string
      app_service:
        description: ECS Service Name
        default: "app-service"
        type: string
      database_name:
        description: Name of the database to create
        default: "ai_camera_log"
        type: string
        required: true

concurrency: ci-${{ github.repository }}-docker-pipeline

jobs:
  docker:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ inputs.aws_region }}

      - name: Create S3 bucket for Terraform state
        run: |
          aws s3api create-bucket --bucket ${{ inputs.backend_s3_bucket }} --region ${{ inputs.aws_region }} --create-bucket-configuration LocationConstraint=${{ inputs.aws_region }} || echo "Bucket already exists"
          aws s3api put-bucket-versioning --bucket ${{ inputs.backend_s3_bucket }} --versioning-configuration Status=Enabled || echo "Versioning already enabled"

      - name: Create DynamoDB table for state locking
        run: |
          aws dynamodb create-table \
            --table-name ${{ inputs.backend_dynamodb_table }} \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST || echo "Table already exists"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Prepare ECR repo name based on the GitHub repository
        shell: bash
        run: |
          set -eux
          repo="${GITHUB_REPOSITORY,,}"
          echo "ECR_REPO_NAME=${repo//\//_}" >> $GITHUB_ENV

      - name: Generate Image Tag
        id: generate-tag
        run: |
          TIMESTAMP=$(date +'%Y%m%d%H%M%S')
          COMMIT_HASH=$(git rev-parse --short HEAD)
          NEW_TAG="snapshot-${TIMESTAMP}-${COMMIT_HASH}"
          echo "IMAGE_TAG=$NEW_TAG" >> $GITHUB_ENV

      - name: Terraform Init
        shell: bash
        run: |
          terraform init -upgrade -reconfigure \
            -backend-config='region=${{ inputs.aws_region }}' \
            -backend-config='bucket=${{ inputs.backend_s3_bucket }}' \
            -backend-config='key=docker-ecr/terraform-${{ env.ECR_REPO_NAME }}.tfstate' \
            -backend-config='dynamodb_table=${{ inputs.backend_dynamodb_table }}'
        working-directory: ./infra

      - name: Terraform Apply
        shell: bash
        run: |
          set -eux
          terraform apply \
            -var 'repository_name=${{ env.ECR_REPO_NAME }}' \
            -var 'aws_account_id=${{ inputs.aws_account_id }}' \
            -var 'aws_region=${{ inputs.aws_region }}' \
            -var 'life_cycle_policy=${{ inputs.lifecycle_policy_file }}' \
            -var 'postgres_password=${{ secrets.POSTGRES_PASSWORD }}' \
            -var 'db_password=${{ secrets.POSTGRES_PASSWORD }}' \
            -var 'image_tag=${{ env.IMAGE_TAG }}' \
            -var 'ecs_cluster_name=${{ inputs.ecs_cluster_name }}' \
            -var 'app_service=${{ inputs.app_service }}' \
            -auto-approve
        working-directory: ./infra

      - name: Retrieve DB and Cache Endpoints
        id: db-cache-endpoints
        run: |
          POSTGRES_HOST=$(terraform output -raw postgres_endpoint)
          POSTGRES_PORT=$(terraform output -raw postgres_port)
          POSTGRES_USER=$(terraform output -raw postgres_user)
          POSTGRES_PASSWORD=$(terraform output -raw postgres_password)
          REDIS_HOST=$(terraform output -raw redis_endpoint)
          REDIS_PORT=$(terraform output -raw redis_port)
          echo "POSTGRES_HOST=$POSTGRES_HOST" >> $GITHUB_ENV
          echo "POSTGRES_PORT=$POSTGRES_PORT" >> $GITHUB_ENV
          echo "POSTGRES_USER=$POSTGRES_USER" >> $GITHUB_ENV
          echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" >> $GITHUB_ENV
        working-directory: ./infra

      - name: Create PostgreSQL Database
        run: |
          psql -h ${{ env.POSTGRES_HOST }} -U ${{ env.POSTGRES_USER }} -p ${{ env.POSTGRES_PORT }} \
          -c "CREATE DATABASE ${{ inputs.database_name }};" || echo "Database already exists"

        env:
          PGPASSWORD: ${{ env.POSTGRES_PASSWORD }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
        with:
          registries: ${{ inputs.aws_account_id }}

      - name: Create .env file for Docker Build
        run: echo "${{ secrets.ENV_FILE_CONTENT }}" > .env

      - name: Write Docker Build Script
        run: |
          cat << 'EOF' > docker-build.sh
          #!/bin/bash
          set -e

          # Check arguments
          if [ $# -ne 6 ]; then
            echo "Usage: $0 <docker_build_dir> <path_to_dockerfile> <aws_account_id> <aws_region> <ecr_repository> <image_tag>"
            exit 1
          fi

          # Assign variables
          DOCKER_BUILD_DIR=$1
          DOCKERFILE_PATH=$2
          AWS_ACCOUNT_ID=$3
          AWS_REGION=$4
          ECR_REPOSITORY=$5
          IMAGE_TAG=$6

          # Set ECR registry URL
          ECR_REGISTRY="${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"

          # Load .env file and parse as Docker build arguments
          BUILD_ARGS=""
          if [ -f .env ]; then
            while IFS= read -r line; do
              if [[ "$line" =~ ^[A-Za-z_][A-Za-z0-9_]*=.*$ ]]; then
                var_name="${line%%=*}"
                var_value="${line#*=}"
                BUILD_ARGS+=" --build-arg $var_name=$var_value"
              fi
            done < .env
          fi

          # Login to ECR
          echo "Logging into Amazon ECR..."
          aws ecr get-login-password --region "$AWS_REGION" | docker login --username AWS --password-stdin "$ECR_REGISTRY"

          # Build and push Docker image
          echo "Building Docker image..."
          docker buildx build "$DOCKER_BUILD_DIR" \
            -f "$DOCKERFILE_PATH" \
            $BUILD_ARGS \
            -t "$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" \
            --push

          echo "Docker image $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG built and pushed successfully."
          EOF

      - name: Make Docker Build Script Executable
        run: chmod +x docker-build.sh

      - name: Execute Docker Build Script
        shell: bash
        run: |
          ./docker-build.sh "${{ inputs.docker_build_dir }}" "${{ inputs.path_to_dockerfile }}" \
          "${{ inputs.aws_account_id }}" "${{ inputs.aws_region }}" \
          "${{ env.ECR_REPO_NAME }}" "${{ env.IMAGE_TAG }}"


      - name: Update ECS Service with New Image
        run: |
          aws ecs update-service \
            --cluster ${{ inputs.ecs_cluster_name }} \
            --service ${{ inputs.app_service }} \
            --force-new-deployment
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ inputs.aws_region }}
