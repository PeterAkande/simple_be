name: Docker image build and publish
on:
  workflow_dispatch:
    inputs:
      path_to_dockerfile:
        description: Path to the Dockerfile (default = 'Dockerfile')
        default: "Dockerfile"
        type: string
      docker_build_dir:
        description: Docker build directory (default = '.')
        default: "."
        type: string
      lifecycle_policy_file:
        description: Path to the lifecycle policy JSON file (default = 'policy.json')
        default: "../build/policy.json"
        type: string
      backend_s3_bucket:
        description: Name of the S3 bucket for Terraform backend
        default: "terraform-backend-primary"
        type: string
      aws_account_id:
        description: AWS Account ID
        type: string
        default: "954614735297"
      aws_region:
        description: Target AWS Region
        default: "us-west-2"
        type: string
      backend_dynamodb_table:
        description: DynamoDB table for State lock
        default: "terraform-backend-ddb"
        type: string
      ecs_cluster_name:
        description: ECS Cluster Name
        default: "app_cluster"
        type: string
      app_service:
        description: ECS Service Name
        default: "app-service"
        type: string
      database_name:
        description: Name of the database to create
        default: "ai_camera_log"
        type: string
        required: true

concurrency: ci-${{ github.repository }}-docker-pipeline

jobs:
  docker:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ inputs.aws_region }}

      - name: Create S3 bucket for Terraform state
        run: |
          aws s3api create-bucket --bucket ${{ inputs.backend_s3_bucket }} --region ${{ inputs.aws_region }} --create-bucket-configuration LocationConstraint=${{ inputs.aws_region }} || echo "Bucket already exists"
          aws s3api put-bucket-versioning --bucket ${{ inputs.backend_s3_bucket }} --versioning-configuration Status=Enabled || echo "Versioning already enabled"

      - name: Create DynamoDB table for state locking
        run: |
          aws dynamodb create-table \
            --table-name ${{ inputs.backend_dynamodb_table }} \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST || echo "Table already exists"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Prepare ECR repo name based on the GitHub repository
        shell: bash
        run: |
          set -eux
          repo="${GITHUB_REPOSITORY,,}"
          echo "ECR_REPO_NAME=${repo//\//_}" >> $GITHUB_ENV

      - name: Generate Image Tag
        id: generate-tag
        run: |
          TIMESTAMP=$(date +'%Y%m%d%H%M%S')
          COMMIT_HASH=$(git rev-parse --short HEAD)
          NEW_TAG="snapshot-${TIMESTAMP}-${COMMIT_HASH}"
          echo "IMAGE_TAG=$NEW_TAG" >> $GITHUB_ENV

      - name: Terraform Init
        shell: bash
        run: |
          terraform init -upgrade -reconfigure \
            -backend-config='region=${{ inputs.aws_region }}' \
            -backend-config='bucket=${{ inputs.backend_s3_bucket }}' \
            -backend-config='key=docker-ecr/terraform-${{ env.ECR_REPO_NAME }}.tfstate' \
            -backend-config='dynamodb_table=${{ inputs.backend_dynamodb_table }}'
        working-directory: ./infra

      - name: Terraform Apply
        shell: bash
        run: |
          set -eux
          terraform apply \
            -var 'repository_name=${{ env.ECR_REPO_NAME }}' \
            -var 'aws_account_id=${{ inputs.aws_account_id }}' \
            -var 'aws_region=${{ inputs.aws_region }}' \
            -var 'life_cycle_policy=${{ inputs.lifecycle_policy_file }}' \
            -var 'postgres_password=${{ secrets.POSTGRES_PASSWORD }}' \
            -var 'db_password=${{ secrets.POSTGRES_PASSWORD }}' \
            -var 'image_tag=${{ env.IMAGE_TAG }}' \
            -var 'ecs_cluster_name=${{ inputs.ecs_cluster_name }}' \
            -var 'app_service=${{ inputs.app_service }}' \
            -auto-approve
        working-directory: ./infra

      - name: Retrieve DB and Cache Endpoints
        id: db-cache-endpoints
        run: |
          POSTGRES_HOST=$(terraform output -raw postgres_endpoint)
          POSTGRES_PORT=$(terraform output -raw postgres_port)
          POSTGRES_USER=$(terraform output -raw postgres_user)
          POSTGRES_PASSWORD=$(terraform output -raw postgres_password)
          REDIS_HOST=$(terraform output -raw redis_endpoint)
          REDIS_PORT=$(terraform output -raw redis_port)
          echo "POSTGRES_HOST=$POSTGRES_HOST" >> $GITHUB_ENV
          echo "POSTGRES_PORT=$POSTGRES_PORT" >> $GITHUB_ENV
          echo "POSTGRES_USER=$POSTGRES_USER" >> $GITHUB_ENV
          echo "POSTGRES_PASSWORD=$POSTGRES_PASSWORD" >> $GITHUB_ENV
        working-directory: ./infra

      - name: Create PostgreSQL Database
        run: |
          psql -h ${{ env.POSTGRES_HOST }} -U ${{ env.POSTGRES_USER }} -p ${{ env.POSTGRES_PORT }} \
          -c "CREATE DATABASE ${{ inputs.database_name }};" || echo "Database already exists"

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
        with:
          registries: ${{ inputs.aws_account_id }}

      - name: Create .env file for Docker Build
        run: echo "${{ secrets.ENV_FILE_CONTENT }}" > .env

      - name: Build, tag, and push image to Amazon ECR
        id: build-publish
        shell: bash
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ${{ env.ECR_REPO_NAME }}
          IMAGE_TAG: ${{ env.IMAGE_TAG }}
          POSTGRES_HOST: ${{ env.POSTGRES_HOST }}
          POSTGRES_PORT: ${{ env.POSTGRES_PORT }}
          POSTGRES_USER: ${{ env.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ env.POSTGRES_PASSWORD }}
          REDIS_HOST: ${{ env.REDIS_HOST }}
          REDIS_PORT: ${{ env.REDIS_PORT }}
        run: |
          docker build "${{ inputs.docker_build_dir }}" -f "${{ inputs.path_to_dockerfile }}" \
            --env-file .env \
            --build-arg POSTGRES_HOST=$POSTGRES_HOST \
            --build-arg POSTGRES_PORT=$POSTGRES_PORT \
            --build-arg POSTGRES_USER=$POSTGRES_USER \
            --build-arg POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
            --build-arg DATABASE_NAME=${{inputs.database_name}} \
            --build-arg REDIS_HOST=$REDIS_HOST \
            --build-arg REDIS_PORT=$REDIS_PORT \
            -t "$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          docker push "$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          echo "IMAGE $IMAGE_TAG is pushed to $ECR_REGISTRY/$ECR_REPOSITORY"
          echo "image_tag=$IMAGE_TAG" >> $GITHUB_ENV
          echo "full_image=$ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG" >> $GITHUB_ENV

      - name: Update ECS Service with New Image
        run: |
          aws ecs update-service \
            --cluster ${{ inputs.ecs_cluster_name }} \
            --service ${{ inputs.app_service }} \
            --force-new-deployment
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ inputs.aws_region }}
