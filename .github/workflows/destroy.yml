name: Destroy All resources
on:
  workflow_dispatch:
    inputs:
      path_to_dockerfile:
        description: Path to the Dockerfile (default = 'Dockerfile')
        default: "Dockerfile"
        type: string
      docker_build_dir:
        description: Docker build directory (default = '.')
        default: "."
        type: string
      image_tag:
        description: Tag to apply to images.
        type: string
        default: latest
      lifecycle_policy_file:
        description: Path to the lifecycle policy JSON file (default = 'policy.json')
        default: "../build/policy.json"
        type: string
      backend_s3_bucket:
        description: Name of the S3 bucket for Terraform backend
        default: "terraform-backend-primary"
        type: string
      aws_account_id:
        description: AWS Account ID
        type: string
        default: "954614735297"
      aws_region:
        description: Target AWS Region
        default: "us-west-2"
        type: string
      backend_dynamodb_table:
        description: DynamoDB table for State lock
        default: "terraform-backend-ddb"
        type: string

      ecs_cluster_name:
        description: ECS Cluster Name
        default: "app_cluster"
        type: string

      app_service:
        description: ECS Service Name
        default: "app-service"
        type: string

concurrency: ci-${{ github.repository }}-docker-pipeline

jobs:
  docker:
    runs-on: ubuntu-latest

    permissions:
      id-token: write
      contents: read

    outputs:
      image_tag: ${{ steps.build-publish.outputs.image_tag }}
      full_image: ${{ steps.build-publish.outputs.full_image }}

    steps:
      - uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ inputs.aws_region }}

      - name: Create S3 bucket for Terraform state
        run: |
          aws s3api create-bucket --bucket ${{ inputs.backend_s3_bucket }} --region ${{ inputs.aws_region }} --create-bucket-configuration LocationConstraint=${{ inputs.aws_region }}|| echo "Bucket already exists"
          aws s3api put-bucket-versioning --bucket ${{ inputs.backend_s3_bucket }} --versioning-configuration Status=Enabled || echo "Versioning already enabled"

      - name: Create DynamoDB table for state locking
        run: |
          aws dynamodb create-table \
            --table-name ${{ inputs.backend_dynamodb_table }} \
            --attribute-definitions AttributeName=LockID,AttributeType=S \
            --key-schema AttributeName=LockID,KeyType=HASH \
            --billing-mode PAY_PER_REQUEST || echo "Table already exists"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_wrapper: false

      - name: Prepare ECR repo name based on the GitHub repository
        shell: bash
        run: |
          set -eux
          repo="${GITHUB_REPOSITORY,,}"
          echo "ECR_REPO_NAME=${repo//\//_}" >> $GITHUB_ENV

      - name: TF init
        shell: bash
        run: |
          set -eux
          terraform init -upgrade -reconfigure \
            -backend-config='skip_metadata_api_check=true' \
            -backend-config='skip_region_validation=true' \
            -backend-config='skip_credentials_validation=true' \
            -backend-config='region=${{ inputs.aws_region }}' \
            -backend-config='bucket=${{ inputs.backend_s3_bucket }}' \
            -backend-config='key=docker-ecr/terraform-${{ env.ECR_REPO_NAME }}.tfstate' \
            -backend-config='dynamodb_table=${{ inputs.backend_dynamodb_table }}'
        working-directory: ./infra

      - name: Destroy resources [Tf destroy]
        shell: bash
        run: |
          set -eux
          terraform destroy \
            -var 'repository_name=${{ env.ECR_REPO_NAME }}' \
            -var 'aws_account_id=${{ inputs.aws_account_id }}' \
            -var 'aws_region=${{ inputs.aws_region }}' \
            -var 'life_cycle_policy=${{ inputs.lifecycle_policy_file }}' \
            -var 'postgres_password=${{ secrets.POSTGRES_PASSWORD }}' \
            -var 'db_password=${{ secrets.POSTGRES_PASSWORD }}' \
            -var 'image_tag=${{ env.IMAGE_TAG }}' \
            -var 'ecs_cluster_name=${{ inputs.ecs_cluster_name }}' \
            -var 'app_service=${{ inputs.app_service }}' \
            -auto-approve
        working-directory: ./infra